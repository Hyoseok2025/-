const express = require('express');
const path = require('path');
const fetch = require('node-fetch');
require('dotenv').config();

const FORCE_DEMO = (process.env.FORCE_DEMO === 'true' || process.env.FORCE_DEMO === '1');

// Mask a secret for safe logging (do not print full key)
function maskKey(k) {
  if (!k) return '';
  if (k.length <= 8) return '****';
  return `${k.slice(0,4)}...${k.slice(-4)}`;
}

const STARTUP_KEY_SOURCE = (process.env.OPENAI_API_KEY && !process.env.OPENAI_API_KEY.includes('REPLACE'))
  ? 'OPENAI_API_KEY'
  : (process.env.MY_API_KEY ? 'MY_API_KEY' : 'none');

const STARTUP_KEY_PREVIEW = STARTUP_KEY_SOURCE === 'OPENAI_API_KEY'
  ? maskKey(process.env.OPENAI_API_KEY)
  : (STARTUP_KEY_SOURCE === 'MY_API_KEY' ? maskKey(process.env.MY_API_KEY) : null);
const app = express();
const PORT = process.env.PORT || 3000;

app.use(express.json());

// ========== Rate Limiting & Security ==========
const requestCounts = new Map();
const RATE_LIMIT_WINDOW = 60000; // 1 minute
const MAX_REQUESTS_PER_MINUTE = 30;

function isRateLimited(ip) {
  const now = Date.now();
  if (!requestCounts.has(ip)) {
    requestCounts.set(ip, []);
  }
  
  const times = requestCounts.get(ip);
  const recentRequests = times.filter(t => now - t < RATE_LIMIT_WINDOW);
  
  if (recentRequests.length >= MAX_REQUESTS_PER_MINUTE) {
    return true;
  }
  
  recentRequests.push(now);
  requestCounts.set(ip, recentRequests);
  return false;
}

// ========== Diagnostics & Canned Responses ==========
let lastOpenAIStatus = { status: null, timestamp: null, body: null };

// Simple in-memory cache for canned responses per character (could be expanded)
const cannedResponses = {
  horn: "ÌïòÌïòÌïò! Ï†ÑÏû• Í≤ΩÌóòÏúºÎ°ú ÎßêÌïòÏûêÎ©¥, ÎÑ§Í∞Ä Îã§Ïùå ÏàòÎ•º ÎÇ¥Í∏∞ Ï†ÑÏóê ÎÇ¥Í≤å Î¨ªÍ±∞Îùº. Í∞ïÌïòÍ≤å, Í∑∏Îü¨ÎÇò Ïã†Ï§ëÌïòÍ≤å.",
  hwarin: "Í≤ÄÏùÄ ÎßàÏùåÏùÑ Îã§Ïä§Î¶¨Í≥† Î™∏ÏùÑ Î∞îÎ°úÏû°ÏïÑÎùº. ÏûêÏÑ∏Í∞Ä ÌùîÎì§Î¶¨Î©¥ Í∏∞Ïà†ÎèÑ ÌùîÎì§Î¶∞Îã§.",
  kai: "Ïñ¥Ïù¥ Ï±îÌîºÏñ∏, Î∂ÄÌíàÏùÄ Ïó¨Í∏∞ÏÑú Íµ¨Ìï¥. Ïã∏Í≤å Ìï¥Ï§ÑÍ≤å. Îã§ÏùåÏóî Îçî Í∞ïÌïú ÏÇΩÏßàÎ°ú ÎèåÎ†§Ï§ÑÍ≤å~"
};

// small LRU-like cache for demo responses (keyed by character)
const demoCache = new Map();
function cacheDemoResponse(characterKey, response) {
  demoCache.set(characterKey, { response, ts: Date.now() });
  // keep cache small
  if (demoCache.size > 10) {
    const firstKey = demoCache.keys().next().value;
    demoCache.delete(firstKey);
  }
}


// ========== Middleware ==========
app.use((req, res, next) => {
  res.header('X-Content-Type-Options', 'nosniff');
  res.header('X-Frame-Options', 'DENY');
  res.header('X-XSS-Protection', '1; mode=block');
  next();
});

// Serve static site (index.html and assets)
app.use(express.static(path.join(__dirname), { 
  index: 'index.html',
  setHeaders: (res, filepath) => {
    if (filepath.endsWith('.html')) {
      res.header('Cache-Control', 'no-cache, no-store, must-revalidate');
    }
  }
}));

// Fallback to index.html for SPA routing
// (SPA fallback moved below after API routes)

// ========== API: Chat Completions Proxy ==========
app.post('/api/chat', (req, res) => {
  const clientIp = req.ip || req.connection.remoteAddress;
  
  // Rate limiting
  if (isRateLimited(clientIp)) {
    return res.status(429).json({ 
      error: { message: 'Too many requests. Please try again later.' } 
    });
  }

  // Support either OPENAI_API_KEY (preferred) or MY_API_KEY (alternate)
  const OPENAI_KEY = process.env.OPENAI_API_KEY || process.env.MY_API_KEY;
  
  // If force-demo is enabled, or key is not set / is placeholder, return demo response
  if (FORCE_DEMO || !OPENAI_KEY || OPENAI_KEY.includes('REPLACE')) {
    return res.status(200).json({
      choices: [{
        message: {
          content: "ÏïàÎÖïÌïòÏÑ∏Ïöî! ÏÑúÎ≤ÑÍ∞Ä ÌòÑÏû¨ Îç∞Î™® Î™®ÎìúÎ°ú ÎèôÏûë Ï§ëÏûÖÎãàÎã§. Ïã§Ï†ú OpenAI Ìò∏Ï∂úÏùÑ ÏÇ¨Ïö©ÌïòÎ†§Î©¥ `.env`Ïóê Ïú†Ìö®Ìïú `OPENAI_API_KEY`Î•º ÏÑ§Ï†ïÌïòÍ±∞ÎÇò `FORCE_DEMO=false`Î°ú Î≥ÄÍ≤ΩÌïòÍ≥† ÏÑúÎ≤ÑÎ•º Ïû¨ÏãúÏûëÌïòÏÑ∏Ïöî."
        }
      }]
    });
  }

  try {
    const { model, messages } = req.body;
    
    if (!messages || !Array.isArray(messages)) {
      return res.status(400).json({ 
        error: { message: 'Invalid request: missing or invalid messages array.' } 
      });
    }

    // Forward to OpenAI with conservative token limits to avoid quota spikes
    const modelToUse = model || 'gpt-3.5-turbo';
    const requestedMax = parseInt(req.body.max_tokens || '128', 10) || 128;
    const maxTokens = Math.min(Math.max(requestedMax, 16), 256); // clamp between 16 and 256

    // Forward to OpenAI
    fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${OPENAI_KEY}`
      },
      body: JSON.stringify({ 
        model: modelToUse,
        messages,
        max_tokens: maxTokens,
        temperature: 0.7
      })
    }).then(response => {
      // update lastOpenAIStatus
      return response.text().then(bodyText => {
        let parsed = null;
        try { parsed = bodyText ? JSON.parse(bodyText) : null; } catch (e) { parsed = { raw: bodyText }; }
        lastOpenAIStatus = { status: response.status, timestamp: new Date().toISOString(), body: (parsed && parsed.error && parsed.error.message) ? parsed.error.message : (typeof bodyText === 'string' ? bodyText.slice(0, 500) : null) };

        // If OpenAI returns 429 (quota), fall back to canned/demo response instead of propagating 429
        if (response.status === 429) {
          console.warn('OpenAI returned 429; returning canned/demo response instead.');
          const charKey = req.body.character;
          const canned = (charKey && cannedResponses[charKey]) ? cannedResponses[charKey] : "Ï£ÑÏÜ°Ìï©ÎãàÎã§ ‚Äî ÌòÑÏû¨ OpenAI ÏÇ¨Ïö©ÎüâÏù¥ Ï¥àÍ≥ºÎêòÏñ¥ Ïã§ÏãúÍ∞Ñ ÏùëÎãµÏùÑ Ï†úÍ≥µÌï† Ïàò ÏóÜÏäµÎãàÎã§. Ïû†Ïãú ÌõÑ Îã§Ïãú ÏãúÎèÑÌï¥ Ï£ºÏÑ∏Ïöî.";
          cacheDemoResponse(charKey || 'generic', canned);
          return res.status(200).json({ choices: [{ message: { content: canned } }], original_error: parsed });
        }

        if (!response.ok) {
          // propagate other errors
          return res.status(response.status).json(parsed || { error: { message: 'Unknown error from OpenAI' } });
        }

        // success path: return parsed JSON
        return res.json(parsed);
      });
    }).catch(err => {
      console.error('Error forwarding to OpenAI:', err);
      lastOpenAIStatus = { status: 'network_error', timestamp: new Date().toISOString(), body: err.message };
      // On network/internal error, attempt to return character-specific canned response
      const charKey = req.body.character;
      const cached = demoCache.get(charKey);
      if (cached) {
        return res.status(200).json({ choices: [{ message: { content: cached.response } }], note: 'served from demo cache' });
      }
      const canned = (charKey && cannedResponses[charKey]) ? cannedResponses[charKey] : "Îç∞Î™® ÏùëÎãµ: OpenAI APIÏóê Ï†ëÏÜçÌïòÎäî ÎèôÏïà Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§. ÎÇòÏ§ëÏóê Îã§Ïãú ÏãúÎèÑÌï¥ Ï£ºÏÑ∏Ïöî.";
      cacheDemoResponse(charKey || 'generic', canned);
      return res.status(200).json({ choices: [{ message: { content: canned } }], error: { message: 'Failed to reach OpenAI API.' } });
    });

  } catch (err) {
    console.error('Error processing request:', err);
    res.status(500).json({ error: { message: err.message } });
  }
});

// ========== Health Check ==========
app.get('/api/health', (req, res) => {
  res.json({ status: 'ok', timestamp: new Date().toISOString(), lastOpenAIStatus });
});

// Diagnostics endpoint: show last OpenAI status, FORCE_DEMO, key source and basic rate info
app.get('/api/diagnostics', (req, res) => {
  const rateInfo = {
    trackedClients: requestCounts.size,
    windowMs: RATE_LIMIT_WINDOW,
    maxRequestsPerMinute: MAX_REQUESTS_PER_MINUTE
  };
  res.json({
    status: 'ok',
    timestamp: new Date().toISOString(),
    lastOpenAIStatus,
    FORCE_DEMO,
    key_source: STARTUP_KEY_SOURCE,
    key_preview: STARTUP_KEY_PREVIEW,
    rateInfo
  });
});

// Fallback to index.html for SPA routing (non-API routes)
app.get(/^(?!\/api)(?!.*\.(js|css|json|jpg|png|gif|svg|ico|woff|woff2)$).*$/, (req, res) => {
  res.sendFile(path.join(__dirname, 'index.html'));
});

// ========== Start Server ==========
app.listen(PORT, '0.0.0.0', () => {
  console.log(`üöÄ Server listening on http://localhost:${PORT}`);
  console.log(`üìù API Endpoint: POST http://localhost:${PORT}/api/chat`);
  console.log(`üíä Health Check: GET http://localhost:${PORT}/api/health`);
  if (FORCE_DEMO) {
    console.log(`‚ö†Ô∏è  FORCE_DEMO is enabled ‚Äî server will return demo responses.`);
  }

  // Log which environment variable will be used for the API key (masked)
  if (STARTUP_KEY_SOURCE === 'OPENAI_API_KEY') {
    console.log(`üîë Using API key from OPENAI_API_KEY (masked): ${STARTUP_KEY_PREVIEW}`);
  } else if (STARTUP_KEY_SOURCE === 'MY_API_KEY') {
    console.log(`üîë Using API key from MY_API_KEY (masked): ${STARTUP_KEY_PREVIEW}`);
    console.log('   Tip: You can rename to OPENAI_API_KEY to prefer that variable.');
  } else {
    console.log(`‚ö†Ô∏è  No API key found in environment. Server will return demo responses.`);
    console.log(`   Set OPENAI_API_KEY or MY_API_KEY in .env to enable real API calls.`);
  }
});
